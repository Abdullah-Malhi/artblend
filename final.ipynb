{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "resnet = tf.keras.applications.resnet50.ResNet50(weights='imagenet')\n",
    "# Content layer where will pull our feature maps\n",
    "content_layers = ['conv5_block1_1_bn'] \n",
    "\n",
    "# Style layer we are interested in\n",
    "style_layers = ['conv5_block1_1_bn','conv2_block1_2_bn'#,'conv1'\n",
    "               ]\n",
    "\n",
    "num_content_layers = len(content_layers)\n",
    "num_style_layers = len(style_layers)\n",
    "# Function to create the style transfer model\n",
    "def get_model(style_layers, content_layers):\n",
    "    \"\"\"Creates a model that outputs intermediate layers of ResNet50.\n",
    "    \n",
    "    Args:\n",
    "        style_layers: List of layer names for style representation.\n",
    "        content_layers: List of layer names for content representation.\n",
    "        \n",
    "    Returns:\n",
    "        A Keras model that takes image inputs and outputs the specified intermediate layers.\n",
    "    \"\"\"\n",
    "    # Load the pre-trained ResNet50 model\n",
    "    resnet = tf.keras.applications.ResNet50(include_top=False, weights='imagenet')\n",
    "    resnet.trainable = False\n",
    "    \n",
    "    # Get the output layers corresponding to style and content layers\n",
    "    style_outputs = [resnet.get_layer(name).output for name in style_layers]\n",
    "    content_outputs = [resnet.get_layer(name).output for name in content_layers]\n",
    "    \n",
    "    # Concatenate the outputs for both style and content layers\n",
    "    model_outputs = style_outputs + content_outputs\n",
    "    \n",
    "    # Define the model with ResNet50 input and the selected intermediate layers as outputs\n",
    "    model = models.Model(resnet.input, model_outputs)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_style_transfer(content_path, style_path, model_weights_path):\n",
    "\n",
    "    # Load the pre-trained model with loaded weights\n",
    "    model = get_model(style_layers, content_layers)\n",
    "    model.load_weights(model_weights_path)\n",
    "\n",
    "    # Load and process content and style images\n",
    "    content_image = load_and_process_img(content_path)\n",
    "    style_image = load_and_process_img(style_path)\n",
    "\n",
    "    # Convert images to tensors and variables\n",
    "    content_image = tf.Variable(content_image, dtype=tf.float32)\n",
    "    style_image = tf.Variable(style_image, dtype=tf.float32)\n",
    "\n",
    "    # Function to calculate total loss (replace with your saved loss functions)\n",
    "    def total_loss(processed_image):\n",
    "        content_loss = content_feature_loss(processed_image, content_features)\n",
    "        style_loss = style_feature_loss(processed_image, style_features)\n",
    "        return content_loss + style_loss\n",
    "\n",
    "    # Feature extraction from content and style images\n",
    "    content_features = ...  # Extract content features using the model (forward pass)\n",
    "    style_features = ...  # Extract style features using the model (forward pass)\n",
    "\n",
    "    # Perform style transfer using a single forward pass and optimization loop\n",
    "    init_image = tf.zeros_like(content_image)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
